import torch
import numpy as np
from tqdm import tqdm
from collections import defaultdict
import config
from dataset import prepare_dataloaders
from model import CLIPModel
import torch.nn.functional as F

# --- [ì„¤ì •] ----------------------
K_SHOT_LIST = [1, 3, 5, 10]  # íŒíŠ¸ ê°œìˆ˜
K_CANDIDATES = 256           # ê²½ìŸì ìˆ˜ (ì •ë‹µ 1 + ì˜¤ë‹µ 255)
# ---------------------------------

@torch.no_grad()
def evaluate_few_shot_benchmark(model, dataloader, device, k_shots=[1, 5], k_candidates=256):
    model.eval()
    print(f"\n" + "="*60)
    print(f"ğŸ”¬ Running Few-Shot Benchmark Evaluation")
    print(f"   - Condition: {k_candidates} Candidates (1 True + {k_candidates-1} Decoys)")
    print(f"   - Logic: Average K spectra -> Rank against {k_candidates} candidates")
    print("="*60)

    # 1. ë°ì´í„° ì¸ì½”ë”© ë° ê·¸ë£¹í•‘
    print("Encoding test set and grouping by SMILES...")
    
    mol_to_specs = defaultdict(list)
    mol_to_text_emb = {}
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for batch in tqdm(dataloader, desc="Encoding"):
        peak_sequence = batch['peak_sequence'].to(device).float()
        peak_mask = batch['peak_mask'].to(device)
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        
        # í…ìŠ¤íŠ¸ ë””ì½”ë”©
        from transformers import AutoTokenizer
        tokenizer = AutoTokenizer.from_pretrained(config.TEXT_ENCODER['model_name'])
        smiles_list = tokenizer.batch_decode(input_ids, skip_special_tokens=True)
        
        # ì„ë² ë”© ì¶”ì¶œ
        with torch.cuda.amp.autocast():
            spec_emb = model.ms_encoder(peak_sequence, peak_mask)
            text_emb = model.text_encoder(input_ids, attention_mask)
            
        spec_emb = spec_emb.cpu()
        text_emb = text_emb.cpu()
        
        for i, smile in enumerate(smiles_list):
            smile_key = smile.replace(" ", "") # ê³µë°± ì œê±°
            mol_to_specs[smile_key].append(spec_emb[i])
            if smile_key not in mol_to_text_emb:
                mol_to_text_emb[smile_key] = text_emb[i]

    # 2. ì „ì²´ í›„ë³´êµ°(Candidate Pool) êµ¬ì¶•
    unique_smiles = list(mol_to_text_emb.keys())
    candidate_embeddings = torch.stack([mol_to_text_emb[s] for s in unique_smiles]) # [N_total, Dim]
    candidate_embeddings = F.normalize(candidate_embeddings, p=2, dim=1)
    
    print(f"\nTotal Unique Molecules in DB: {len(unique_smiles)}")
    
    # 3. K-Shot ë³„ ì„±ëŠ¥ ì¸¡ì •
    for k in k_shots:
        print(f"\n--- Testing {k}-Shot Retrieval (vs {k_candidates} candidates) ---")
        
        r1_hits = 0
        total_queries = 0
        
        # ëœë¤ ì‹œë“œ ê³ ì • (ì¬í˜„ì„± ìœ„í•´)
        torch.manual_seed(config.RANDOM_SEED)
        
        for target_idx, target_smile in enumerate(tqdm(unique_smiles, desc=f"Evaluating (K={k})")):
            specs = mol_to_specs[target_smile]
            
            # ìŠ¤í™íŠ¸ëŸ¼ì´ Kê°œ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
            if len(specs) < k:
                continue
                
            # [Step A] íŒíŠ¸ ìƒì„± (Kê°œ í‰ê· )
            indices = np.random.choice(len(specs), k, replace=False)
            selected_specs = torch.stack([specs[i] for i in indices])
            query_vec = torch.mean(selected_specs, dim=0, keepdim=True)
            query_vec = F.normalize(query_vec, p=2, dim=1)
            
            # [Step B] ì „ì²´ ìœ ì‚¬ë„ ê³„ì‚° (1 vs 4917)
            # ì¼ë‹¨ ì „ì²´ë‘ ë‹¤ ê³„ì‚°í•˜ê³  ë‚˜ì„œ, ë‚˜ì¤‘ì— 256ê°œë§Œ ì¶”ë ¤ë‚´ëŠ” ê²Œ êµ¬í˜„ì´ í¸í•¨
            sim_scores = torch.matmul(query_vec, candidate_embeddings.T).squeeze() # [N_total]
            
            # [Step C] 256ê°œ í›„ë³´êµ° êµ¬ì„± (Subsampling)
            # 1. ì •ë‹µ ì ìˆ˜ í™•ë³´
            score_target = sim_scores[target_idx]
            
            # 2. ì˜¤ë‹µ ì ìˆ˜ë“¤ë§Œ ëª¨ìœ¼ê¸° (ìì‹  ì œì™¸)
            # ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ìê¸° ìì‹ (target_idx)ì„ ëº€ ë‚˜ë¨¸ì§€ ì ìˆ˜ë§Œ ê°€ì ¸ì˜´
            mask = torch.ones_like(sim_scores, dtype=torch.bool)
            mask[target_idx] = False
            negative_scores = sim_scores[mask]
            
            # 3. ëœë¤ìœ¼ë¡œ 255ê°œ ì˜¤ë‹µ ë½‘ê¸°
            n_neg = min(len(negative_scores), k_candidates - 1)
            perm = torch.randperm(len(negative_scores))[:n_neg]
            sampled_negatives = negative_scores[perm]
            
            # [Step D] ë­í‚¹ í™•ì¸ (1 vs 256)
            # ë‚´ ì ìˆ˜ê°€ ë½‘íŒ ì˜¤ë‹µë“¤(255ê°œ) ì¤‘ ê°€ì¥ ë†’ì€ ì ìˆ˜ë³´ë‹¤ í¬ë©´ 1ë“±
            if score_target > sampled_negatives.max():
                r1_hits += 1
                
            total_queries += 1
            
        # ê²°ê³¼ ì¶œë ¥
        if total_queries > 0:
            print(f"  Samples evaluated: {total_queries}")
            print(f"  Benchmark R@1 : {r1_hits/total_queries*100:.2f}%")
        else:
            print("  No samples with enough spectra.")

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else 'cpu')
    print(f"Using Device: {device}")
    
    _, test_loader = prepare_dataloaders()
    
    model = CLIPModel().to(device)
    checkpoint = torch.load(f"{config.CHECKPOINT_DIR}/best_model.pt", map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"Loaded model (Epoch {checkpoint['epoch']})")
    
    # 256ê°œ í›„ë³´êµ° ì„¤ì •
    evaluate_few_shot_benchmark(model, test_loader, device, k_shots=K_SHOT_LIST, k_candidates=256)

if __name__ == '__main__':
    main()